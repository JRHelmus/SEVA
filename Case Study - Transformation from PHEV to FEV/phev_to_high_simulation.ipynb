{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import pandas\n",
    "import pickle\n",
    "import numpy\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'environment' from '/home/ignavermeulen/modeling_charging_behavior/environment.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import datetime\n",
    "\n",
    "import simulation\n",
    "import data_handler\n",
    "import environment\n",
    "import agent \n",
    "\n",
    "import imp\n",
    "imp.reload(agent)\n",
    "imp.reload(simulation)\n",
    "imp.reload(data_handler)\n",
    "imp.reload(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Initialization\n",
      "\tINFO: Loading sessions took 1.79 seconds\n",
      "\tINFO: Detailed preprocessing took 2.49 seconds\n",
      "\tINFO: Initializing (load_and_use) 10 random agents\n",
      "\t\tINFO: 10 of 10 agents are initialized\n",
      "\t\t\tINFO: 10 of 2287 users are processed\n",
      "\t\tINFO: Initialized 10 agents in 18.35 seconds\n",
      "\tINFO: Initialization took 20.95 seconds\n",
      "CPU times: user 20.3 s, sys: 824 ms, total: 21.2 s\n",
      "Wall time: 21.3 s\n"
     ]
    }
   ],
   "source": [
    "%time sim_phev_to_high = simulation.Simulation(\"data/input_parameters/parameters.json\", \\\n",
    "    overwrite_parameters = {'agent_initialization': 'load_and_use', \\\n",
    "    'filepath_agent_database': 'data/agent_database/all_non_changing_agents/', 'number_of_agents': 10, \\\n",
    "    'transform_parameters': { \\\n",
    "            \"prob_no_transform\": 0.0, \\\n",
    "            \"prob_to_low_fev\": 0.0, \\\n",
    "            \"prob_to_high_fev\": 1.0 \\\n",
    "          }, \\\n",
    "    'agent_creation_method': 'random', \\\n",
    "    'skip_high_fev_agents': True, \\\n",
    "    'skip_low_fev_agents': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time sim_phev_to_high.repeat_simulation(repeat = 1, method = 'relMAE', measures = []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = list(sim_phev_to_high.agents.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.all_simulated_sessions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_sessions = pandas.DataFrame()\n",
    "for a in sim_phev_to_high.agents.values():\n",
    "    all_sessions = all_sessions.append(a.all_simulated_sessions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35680"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_file = 'data/sessions/ChargeSessions_simulated_phev_to_high.pkl'\n",
    "with open(path_to_file, 'wb') as data_file:\n",
    "    pickle.dump(all_sessions, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath_agent_database = 'data/agent_database/phev_to_high_transformed_agents_test/'\n",
    "for agent in sim_phev_to_high.agents.values():\n",
    "    my_agent_data = agent._get_agent_data()\n",
    "    with open(filepath_agent_database + agent.ID + '.pkl', 'wb') as agent_file:\n",
    "        pickle.dump(my_agent_data, agent_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sim_repeat in range(5):\n",
    "    for agent in sim_phev_to_high.values():\n",
    "        agent.all_simulated_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_agent(directory, agent_data, agent_ID):\n",
    "    with open(directory + agent_ID + '.pkl', 'wb') as agent_file:\n",
    "        pickle.dump(agent_data, agent_file)\n",
    "        \n",
    "def load_agent(directory, agent_ID):\n",
    "    with open(directory + agent_ID + '.pkl', 'rb') as agent_file:\n",
    "        agent_data = pickle.load(agent_file)\n",
    "    return agent_data\n",
    "\n",
    "def load_dict_agents_data(directory, skip_changing_users = True):\n",
    "    result = {}\n",
    "    all_agent_IDs = set([files[:-4] for files in os.listdir(directory) if files[0] != '.'])\n",
    "    for ID in all_agent_IDs:\n",
    "        if skip_changing_users and (ID in high_to_low_users or ID in low_to_high_users):\n",
    "            continue\n",
    "        agent_data = load_agent(directory, ID)\n",
    "        if agent_data['user_type'] == 'regulier':\n",
    "            result[ID] = agent_data\n",
    "    return result\n",
    "\n",
    "def get_dataframe_data(data_agents):\n",
    "    stripped_dict = {}\n",
    "    for agent in data_agents:\n",
    "        stripped_dict[agent] = {}\n",
    "        for key, val in data_agents[agent].items():\n",
    "            if (isinstance(val, int) or isinstance(val, float) or isinstance(val, str)):\n",
    "                stripped_dict[agent][key] = val\n",
    "    return pandas.DataFrame.from_dict(stripped_dict, orient = 'index')\n",
    "\n",
    "def load_agent_sessions(directory, data = pandas.DataFrame(), skip_changing_users = True):\n",
    "    if len(data) == 0:\n",
    "        path_to_file = 'data/sessions/ChargeSessions_general_filtered.pkl'\n",
    "        with open(path_to_file, 'rb') as data_file:\n",
    "            data = pickle.load(data_file)\n",
    "    result = {}\n",
    "    all_agent_IDs = set([files[:-4] for files in os.listdir(directory) if files[0] != '.'])\n",
    "    for i, ID in enumerate(all_agent_IDs):\n",
    "        if (i % 200 == 0):\n",
    "            print(\"Loaded sessions for %d of %d agents\" %(i, len(all_agent_IDs)))\n",
    "        if skip_changing_users and (ID in high_to_low_users or ID in low_to_high_users):\n",
    "            continue\n",
    "        df = data.loc[data['ID'] == ID]\n",
    "        df = df.sort_values(by = 'start_connection', inplace = False)\n",
    "        result[ID] = df\n",
    "    return result\n",
    "\n",
    "def update_general_data():\n",
    "    path_to_file = 'data/sessions/ChargeSessions_general.pkl'\n",
    "    with open(path_to_file, 'rb') as data_file:\n",
    "        data = pickle.load(data_file)\n",
    "    df['connection_duration'] = df.apply(lambda row: row.end_connection - row.start_connection, axis = 1)\n",
    "    df = df[df.connection_duration > min_duration_session] \n",
    "    path_to_file = 'data/sessions/ChargeSessions_general_filtered.pkl'\n",
    "    with open(path_to_file, 'wb') as data_file:\n",
    "            pickle.dump(df, data_file)\n",
    "\n",
    "def update_agent_data(agent_dir, agent_ID, data_key, data, in_place = False, agent_data = None):\n",
    "    ''' Updates the given agent with the given data in the database. The key data_key is added to the agent dictionary,\n",
    "        and the data is added as value. This agent is then again saved in the same spot. \n",
    "    '''\n",
    "    if agent_data == None:\n",
    "        agent_data = load_agent(agent_dir, agent_ID)\n",
    "    if not in_place:\n",
    "        agent_data[data_key] = data\n",
    "    save_agent(agent_dir, agent_data, agent_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_to_low_users = ['5D763B2DCBFD274859F43EE1456A1DD0B68F72A82E0A8564372C4BD46B95DAC8',\n",
    "                    '8DD214E9F9611E7D01E662E940AC973BCC34CF45C3D43D3306DFD3F9AEB5075C',\n",
    "                    '9A79FD1E5649B3FA3978C6B7E682571ED5570F5D1A35CDE4E80C6F30DFCFAF2B',\n",
    "                    '09CAA3715AE1BC35FC152487BBD693275E97DE039207824D1063E5A7A0E2DD6E',\n",
    "                    '144984E1475253AC45D743910C4CF344A2D315EA12ACD21AB58971105DEAF522',\n",
    "                    'B8256507B35A603D43CF7437CCC5712F33F1F54B82EB416FEA942725AAD3831C',\n",
    "                    'F32DBA25D91138963F85144783F71A16E4C2CF7D1523F0644A6404B4C2F227C4',\n",
    "                    'F9541CDC30F3E36CEE3EE6954D0AC7D7925C5539D5E751E79AD13734E455ADBC']\n",
    "low_to_high_users = ['6D47DA110FAA422E77B8DA82975F644315AC05C3D0E38B12A80816793452D857',\n",
    "                    '8C45CDFC57F283C9BFB268CBD39725923FF8D22BCDF75E3E4FD054B079872459',\n",
    "                    '9C510710140B57F6EB58CC760CCAE70064D161D0B993741CC479FAF65175B2CB',\n",
    "                    '9D2D9AD61D9BCBF8A3CBBBEE6A031A7152EF2C28235E54CC5E1A478CC9BC9F73',\n",
    "                    '17AFFF335DB8BF72259DD11C23D375ECA607613B2D9E1379AFF0922888A8EE90',\n",
    "                    '53DDDDFF98D9CB22915B054A55F663BFDE941FFD8039A03248E559945C096031',\n",
    "                    '80E9884E3E4B152B66E2B3A2861FE89BE1D48A346C16EF8739F9714F4BD6AEBB',\n",
    "                    '606BD9C4F45EF4BD2710D2C4B178BF7356D2D9437BDF53B5593AB87F35A061B1',\n",
    "                    '17897EE886276B2EA379234AC9112C0816C0C917977A8DB4E3282A3C9BE7D018',\n",
    "                    '918130F5F1FC762D62308F082000F698F77C6CDBD34F9F4915835D484663A509',\n",
    "                    'EDA3B229C2661C6E479A565173F553DB7A10275D5360E542DA626F96832C12C6',\n",
    "                    'F346C8B51850F3D811CCDE0EC612153028C9F69E9B79C1FA9E4F5FA75F470AA9',\n",
    "                    'FDC8791D2EE934F8A1DD22816E149DD2E37E185C985C772D38D44FE74AA207DE',\n",
    "                    'F20D73D834CB2523C7E8E55643E2A7E6467DA5D4B4EBCA3547BC9FE49009E731']\n",
    "wth_are_u_doing_users = ['7DA773D56D9BABA6B82139F286FA593EB0685317075EE743F05A3DDE1A1A552A',\n",
    "                      '62ABF94F3B61963B34B78EA7F062DE8681015F17730270CCAA8F6BD61828889F',\n",
    "                      '70E685BA7C2BC723DA307881476A3E5FC3AD1FCABDDFBF3A5BBA69E8BBB53B94']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.5 s, sys: 1.57 s, total: 53.1 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "% time data_agents = load_dict_agents_data('data/agent_database/all_non_changing_agents/')\n",
    "data_agents_df = get_dataframe_data(data_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_file = 'data/sessions/ChargeSessions_general_filtered.pkl'\n",
    "with open(path_to_file, 'rb') as data_file:\n",
    "    general_data = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/sessions/ChargeSessions_general_expanded_per_agent.pkl', 'rb') as df:\n",
    "    sessions_data_expanded = pickle.load(df)\n",
    "    \n",
    "dfs_phev = []\n",
    "dfs_low_fev = []\n",
    "dfs_high_fev = []\n",
    "\n",
    "for i, a in enumerate(sessions_data_expanded):\n",
    "    if a not in data_agents:\n",
    "        continue\n",
    "    if data_agents[a]['battery_category'] == 'phev':\n",
    "        dfs_phev.append(sessions_data_expanded[a])\n",
    "    elif data_agents[a]['battery_category'] == 'fev_low':\n",
    "        dfs_low_fev.append(sessions_data_expanded[a])\n",
    "    elif data_agents[a]['battery_category'] == 'fev_high':\n",
    "        dfs_high_fev.append(sessions_data_expanded[a])\n",
    "\n",
    "\n",
    "phev_sessions = pandas.concat(dfs_phev)\n",
    "low_fev_sessions = pandas.concat(dfs_low_fev)\n",
    "high_fev_sessions = pandas.concat(dfs_high_fev)\n",
    "\n",
    "phev_sessions['car_type']  = ['phev'] * len(phev_sessions)\n",
    "low_fev_sessions['car_type']  = ['low_fev'] * len(low_fev_sessions)\n",
    "high_fev_sessions['car_type']  = ['high_fev'] * len(high_fev_sessions)\n",
    "\n",
    "all_sessions = pandas.concat([phev_sessions, low_fev_sessions, high_fev_sessions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 2242, took: 0:00:00.000726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 of 2242, took: 0:01:55.249061\n",
      "200 of 2242, took: 0:01:46.285261\n",
      "300 of 2242, took: 0:01:54.933410\n",
      "400 of 2242, took: 0:01:53.219279\n",
      "500 of 2242, took: 0:01:51.797713\n",
      "600 of 2242, took: 0:01:50.956315\n",
      "700 of 2242, took: 0:01:53.129710\n",
      "800 of 2242, took: 0:01:55.880877\n",
      "900 of 2242, took: 0:01:54.239900\n",
      "1000 of 2242, took: 0:02:01.938526\n",
      "1100 of 2242, took: 0:02:00.558754\n",
      "1200 of 2242, took: 0:02:01.527416\n",
      "1300 of 2242, took: 0:02:03.597171\n",
      "1400 of 2242, took: 0:01:57.408693\n",
      "1500 of 2242, took: 0:01:50.927497\n",
      "1600 of 2242, took: 0:01:53.930737\n",
      "1700 of 2242, took: 0:01:59.048626\n",
      "1800 of 2242, took: 0:02:00.222292\n",
      "1900 of 2242, took: 0:02:01.995533\n",
      "2000 of 2242, took: 0:02:00.186659\n",
      "2100 of 2242, took: 0:01:57.449641\n",
      "2200 of 2242, took: 0:01:52.052425\n"
     ]
    }
   ],
   "source": [
    "temp_agent_sessions = {}\n",
    "prev = datetime.datetime.now()\n",
    "for i, a in enumerate(data_agents):\n",
    "    if i % 100 == 0:\n",
    "        print(\"%d of %d, took: %s\" %(i, len(data_agents), datetime.datetime.now() - prev))\n",
    "        prev = datetime.datetime.now()\n",
    "    df = all_sessions.loc[all_sessions.ID == a]\n",
    "    df['previous_location_key'] = df.location_key.shift(1)\n",
    "    df = df[df.previous_location_key != 'NaT']\n",
    "    temp_agent_sessions[a] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['location_key', 'ID', 'start_connection', 'end_connection',\n",
       "       'connection_time_hours', 'kWh', 'city', 'region_abbreviation',\n",
       "       'provider', 'address', 'postal_code', 'district', 'subdistrict',\n",
       "       'latitude', 'longitude', 'amount_of_sockets', 'parking_zone',\n",
       "       'connection_duration', 'shifted_end_connection',\n",
       "       'disconnection_duration', 'disconnection_duration_days',\n",
       "       'connection_duration_days', 'weekday', 'kwh_grouped', 'car_type',\n",
       "       'previous_location_key'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = list(temp_agent_sessions.keys())[0]\n",
    "temp_agent_sessions[agent].columns\n",
    "# len(temp_agent_sessions[agent])\n",
    "# len(temp_agent_sessions[agent].loc[temp_agent_sessions[agent]['disconnection_duration_days'] < 1.0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_nr_sessions = 0\n",
    "total_nr_at_same = 0 \n",
    "fracs = []\n",
    "for a in temp_agent_sessions:\n",
    "    short_sessions = temp_agent_sessions[a].loc[temp_agent_sessions[a]['disconnection_duration'] < pandas.to_timedelta('60min')]\n",
    "    short_sessions = short_sessions.loc[short_sessions['disconnection_duration'] > pandas.to_timedelta('55min')]\n",
    "    nr_short_sessions = len(short_sessions)\n",
    "    if nr_short_sessions == 0:\n",
    "        continue\n",
    "    nr_at_same = len(short_sessions.loc[short_sessions['previous_location_key'] == short_sessions['location_key']])\n",
    "    total_nr_sessions += nr_short_sessions\n",
    "    total_nr_at_same += nr_at_same\n",
    "    fracs.append(nr_at_same / (nr_short_sessions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3883 2466 0.6350759721864537\n"
     ]
    }
   ],
   "source": [
    "print(total_nr_sessions, total_nr_at_same, total_nr_at_same / total_nr_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.658719518051 0.40528841121\n"
     ]
    }
   ],
   "source": [
    "print(numpy.mean(fracs), numpy.std(fracs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_connection_range(session):\n",
    "    ''' This method generates the range of a charging session with the step\n",
    "        size given in the bin_size_dist variable.\n",
    "\n",
    "    Args:\n",
    "        session (Series): The pandas Series from which to get the start and\n",
    "            end times of the range.\n",
    "\n",
    "    Returns:\n",
    "        (DatetimeIndex): Containing Timestamps of the times between the\n",
    "            start of the session and the end of the session with an\n",
    "            interval between those times of the bin size of the simulation.\n",
    "    '''\n",
    "\n",
    "    range_session = pandas.date_range(session['start_connection'], session['end_connection'], freq = '20min')\n",
    "    return (time for time in range_session)\n",
    "\n",
    "def get_activity_patterns_centers(agent_sessions, centers_css):\n",
    "    ''' This method calculates the activity patterns for each center of\n",
    "        an agent.\n",
    "\n",
    "    Args:\n",
    "        agent_sessions (DataFrame): The sessions of the agent.\n",
    "        centers_css (Dict[Tuple[float, float], Dict[str, Any]]): Centers\n",
    "            (lon, lat) as keys and each center being a dictionary with the\n",
    "            keys 'habit' and 'distance'. The value of the habit key is a set\n",
    "            of charging stations (location keys), while the value of the\n",
    "            distance key is a dictionary with the charging stations\n",
    "            (location keys) as keys and their distance to the center (in\n",
    "            meters) as value.\n",
    "\n",
    "    Returns:\n",
    "        activity_patterns (Dict[Tuple[float, float], List[float]]): A\n",
    "            dictionary of activity patterns with the centers as keys.\n",
    "            The activity patterns are lists of probabilities per bin with the\n",
    "            probabilities indicating the chance of being connected to the\n",
    "            center in the time interval of the bin.\n",
    "    '''\n",
    "\n",
    "    dists = {}\n",
    "    if len(agent_sessions) > 0:\n",
    "        for center in centers_css.keys():\n",
    "            cluster_dataframes = [agent_sessions.loc[\n",
    "                agent_sessions['location_key'] == cs] for cs in centers_css[center]['habit']]\n",
    "            cluster_sessions = pandas.concat(cluster_dataframes)\n",
    "            dists[center] = self.get_activity_pattern(cluster_sessions)\n",
    "        return dists\n",
    "\n",
    "    return {center: get_activity_pattern(pandas.DataFrame({}))\n",
    "        for center in centers_css.keys()}\n",
    "\n",
    "def get_activity_pattern(sessions):\n",
    "    ''' This method calculates the activity pattern using the given sessions.\n",
    "\n",
    "    Args:\n",
    "        sessions (DataFrame): The sessions that will be used to\n",
    "            create the activity pattern.\n",
    "\n",
    "    Returns:\n",
    "        (List[float]): The activity pattern being a list of probabilities\n",
    "            per bin with the probabilities indicating the chance of being\n",
    "            connected to the in the time interval of the bin.\n",
    "    '''\n",
    "    offset = pandas.to_datetime('01-01-2000', format='%d-%m-%Y')\n",
    "    times_day = pandas.date_range(offset, offset + pandas.to_timedelta('23:59:59'), freq = '20min')\n",
    "\n",
    "    if len(sessions) == 0:\n",
    "        df = pandas.DataFrame({'times': times_day})\n",
    "        df['0'] = pandas.Series([0] * len(times_day))\n",
    "        df.set_index('times', drop = True, inplace = True)\n",
    "        return [0] * len(times_day)\n",
    "\n",
    "    sessions.all_dates = sessions.apply(lambda row: get_connection_range(row), axis = 1)\n",
    "    list_all_dates = [list(dates) for dates in sessions.all_dates]\n",
    "    times = []\n",
    "    for dates in list_all_dates:\n",
    "        for date in dates:\n",
    "            times.append(date.replace(year = offset.year, month = offset.month, day = offset.day))\n",
    "    df = pandas.DataFrame({'times': times})\n",
    "    df.set_index('times', drop = False, inplace = True)\n",
    "    df = df.groupby(pandas.TimeGrouper(freq = '20min')).count()\n",
    "\n",
    "    if (len(df) < datetime.timedelta(days = 1) / datetime.timedelta(minutes = 20)):\n",
    "        missing_indices = [time for time in times_day\n",
    "            if time not in list(df.times.index)]\n",
    "        missing_series = pandas.Series([0] * len(missing_indices),\n",
    "            index = missing_indices)\n",
    "        return df.times.append(missing_series).sort_index()\n",
    "    else:\n",
    "        return df.times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
